{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c26653-7fe1-4cfd-962d-c45504b15815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a693bb-867a-4722-9723-e79e086cb9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4029401191\n",
      "4034434712\n",
      "4029403119\n",
      "4029401185\n",
      "4034434518\n",
      "4034631313\n",
      "4032969133\n",
      "4030046893\n",
      "4029650113\n",
      "4037427187\n"
     ]
    }
   ],
   "source": [
    "title = \"Data Scientist\"  # Job title\n",
    "location = \"USA\"  # Job location\n",
    "start = 0  # Starting point for pagination\n",
    "# Construct the URL for LinkedIn job search\n",
    "list_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={title}&location={location}&start={start}\"\n",
    "\n",
    "# Send a GET request to the URL and store the response\n",
    "response = requests.get(list_url)\n",
    "\n",
    "#Get the HTML, parse the response and find all list items(jobs postings)\n",
    "list_data = response.text\n",
    "list_soup = BeautifulSoup(list_data, \"html.parser\")\n",
    "page_jobs = list_soup.find_all(\"li\")\n",
    "\n",
    "#Create an empty list to store the job postings\n",
    "id_list = []\n",
    "\n",
    "#Itetrate through job postings to find job ids\n",
    "for job in page_jobs:\n",
    "    base_card_div = job.find(\"div\", {\"class\": \"base-card\"})\n",
    "    job_id = base_card_div.get(\"data-entity-urn\").split(\":\")[3]\n",
    "    print(job_id)\n",
    "    id_list.append(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6699dc9e-bf77-470c-a6b2-4b5bc9e60ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist, Product</td>\n",
       "      <td>Notion</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist, Intern (Undergraduate)</td>\n",
       "      <td>Duolingo</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Flexon Technologies Inc.</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist - Strategy &amp; Insights</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Walgreens</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_title              company_name  \\\n",
       "0                      Data Scientist, Product                    Notion   \n",
       "1       Data Scientist, Intern (Undergraduate)                  Duolingo   \n",
       "2                        Junior Data Scientist  Flexon Technologies Inc.   \n",
       "3  Senior Data Scientist - Strategy & Insights                  LinkedIn   \n",
       "4                               Data Scientist                 Walgreens   \n",
       "\n",
       "                                             job_url  \n",
       "0  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "1  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "2  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "3  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "4  https://www.linkedin.com/jobs-guest/jobs/api/j...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store job information\n",
    "job_list = []\n",
    "\n",
    "# Initialize a set to keep track of added job URLs\n",
    "added_urls = set()\n",
    "\n",
    "# Loop through the list of job IDs and get each URL\n",
    "for job_id in id_list:\n",
    "    # Add a short delay to avoid rate-limiting issues (you can adjust the delay as needed)\n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    \n",
    "    # Construct the URL for each job using the job ID\n",
    "    job_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
    "    \n",
    "    # Check if the job URL is already added\n",
    "    if job_url in added_urls:\n",
    "        continue  # Skip to the next job if it's already in the set\n",
    "    \n",
    "    # Send a GET request to the job URL and parse the response\n",
    "    job_response = requests.get(job_url)\n",
    "\n",
    "    if job_response.status_code == 200:\n",
    "        print(job_response.status_code)\n",
    "        job_soup = BeautifulSoup(job_response.text, \"html.parser\")\n",
    "        \n",
    "        # Create a dictionary to store job details\n",
    "        job_post = {}\n",
    "        \n",
    "        # Try to extract and store the job title\n",
    "        try:\n",
    "            job_post[\"job_title\"] = job_soup.find(\"h2\", {\"class\":\"top-card-layout__title font-sans text-lg papabear:text-xl font-bold leading-open text-color-text mb-0 topcard__title\"}).text.strip()\n",
    "        except:\n",
    "            job_post[\"job_title\"] = None\n",
    "            \n",
    "        # Try to extract and store the company name\n",
    "        try:\n",
    "            job_post[\"company_name\"] = job_soup.find(\"a\", {\"class\": \"topcard__org-name-link topcard__flavor--black-link\"}).text.strip()\n",
    "        except:\n",
    "            job_post[\"company_name\"] = None\n",
    "    \n",
    "        # Add the job URL to the job_post dictionary\n",
    "        job_post[\"job_url\"] = job_url  # Include job URL\n",
    "        \n",
    "        # Append the job details to the job_list\n",
    "        job_list.append(job_post)\n",
    "        \n",
    "        # Add the job URL to the set of added URLs\n",
    "        added_urls.add(job_url)\n",
    "    \n",
    "        # Add a short delay to avoid rate-limiting issues (you can adjust the delay as needed)\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "# Check if the list contains all the desired data\n",
    "job_list\n",
    "\n",
    "# Create a pandas DataFrame using the list of job dictionaries 'job_list'\n",
    "jobs_df = pd.DataFrame(job_list)\n",
    "\n",
    "# Optional: Reset the index after all jobs have been processed\n",
    "jobs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the final DataFrame\n",
    "jobs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b48a7e1-bd58-4b49-8841-2234b3afdd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'job_title': 'Data Scientist, Product',\n",
       "  'company_name': 'Notion',\n",
       "  'job_url': 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4034434712'},\n",
       " {'job_title': 'Data Scientist, Intern (Undergraduate)',\n",
       "  'company_name': 'Duolingo',\n",
       "  'job_url': 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4029403119'},\n",
       " {'job_title': 'Junior Data Scientist',\n",
       "  'company_name': 'Flexon Technologies Inc.',\n",
       "  'job_url': 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4030046893'},\n",
       " {'job_title': 'Senior Data Scientist - Strategy & Insights',\n",
       "  'company_name': 'LinkedIn',\n",
       "  'job_url': 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4029650113'},\n",
       " {'job_title': 'Data Scientist',\n",
       "  'company_name': 'Walgreens',\n",
       "  'job_url': 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4037427187'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the list contains all the desired data\n",
    "job_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721dc3d-3659-4332-8095-e0c225afd070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59927ab4-1a5d-4a99-8172-a2aeb6799352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [job_url]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Set up Chrome options (optional)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (without opening a browser window)\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "\n",
    "# Load the webpage\n",
    "driver.get('https://example.com')  # Replace with your URL\n",
    "\n",
    "# Find the link by its text or other attributes (use appropriate locator strategy)\n",
    "link = driver.find_element(By.LINK_TEXT, \"Click Me\")  # Replace \"Click Me\" with the link text\n",
    "\n",
    "# Click on the link\n",
    "link.click()\n",
    "\n",
    "# Get the current URL after clicking\n",
    "new_url = driver.current_url\n",
    "\n",
    "print(f\"The new URL is: {new_url}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b42ca-f068-4af8-8160-3dcbc0b0710b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
